# Use the official Spark image with Python support
FROM apache/spark-py:v3.5.0 as spark-base

USER root

# Verify Java installation and set JAVA_HOME
RUN java -version && \
    echo "JAVA_HOME=$JAVA_HOME"

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONPATH="/app" \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    SPARK_NO_DAEMONIZE=true

# Install system dependencies
RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        python3-pip \
        python3-dev \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Create necessary directories with proper permissions
RUN mkdir -p data/raw data/processed data/visualization data/archive logs temp \
    && chmod -R 777 data logs temp

# Create a non-root user
RUN useradd -m -s /bin/bash app \
    && chown -R app:app /app

# Switch to non-root user
USER app 